{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f478de34",
   "metadata": {},
   "source": [
    "# Google sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "109eb900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from GoogleNews import GoogleNews\n",
    "from newspaper import Article\n",
    "from newspaper import Config\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "# nltk.download('vader_lexicon') #required for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c91452a",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = dt.date.today()\n",
    "now = now.strftime('%m-%d-%Y')\n",
    "yesterday = dt.date.today() - dt.timedelta(days = 1)\n",
    "yesterday = yesterday.strftime('%m-%d-%Y')\n",
    "\n",
    "# nltk.download('punkt')\n",
    "user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:78.0) Gecko/20100101 Firefox/78.0'\n",
    "config = Config()\n",
    "config.browser_user_agent = user_agent\n",
    "config.request_timeout = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4c7ca6",
   "metadata": {},
   "source": [
    "## Here we give the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b08b909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide the name of the Company or a Ticker: dollar rupee\n",
      "Searching for and analyzing dollar rupee, Please be patient, it might take a while...\n",
      "HTTP Error 429: Too Many Requests\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# save the company name in a variable\n",
    "company_name = input(\"Please provide the name of the Company or a Ticker: \")\n",
    "#As long as the company name is valid, not empty...\n",
    "if company_name != '':\n",
    "    print(f'Searching for and analyzing {company_name}, Please be patient, it might take a while...')\n",
    "\n",
    "    #Extract News with Google News\n",
    "    googlenews = GoogleNews(start=yesterday,end=now)\n",
    "    googlenews.search(company_name)\n",
    "    result = googlenews.result()\n",
    "    #store the results\n",
    "    df = pd.DataFrame(result)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1cc7fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    list =[] #creating an empty list \n",
    "    for i in df.index:\n",
    "        dict = {} #creating an empty dictionary to append an article in every single iteration\n",
    "        article = Article(df['link'][i],config=config) #providing the link\n",
    "        try:\n",
    "          article.download() #downloading the article \n",
    "          article.parse() #parsing the article\n",
    "          article.nlp() #performing natural language processing (nlp)\n",
    "        except:\n",
    "           pass \n",
    "        #storing results in our empty dictionary\n",
    "        dict['Date']=df['date'][i] \n",
    "        dict['Media']=df['media'][i]\n",
    "        dict['Title']=article.title\n",
    "        dict['Article']=article.text\n",
    "        dict['Summary']=article.summary\n",
    "        dict['Key_words']=article.keywords\n",
    "        list.append(dict)\n",
    "    check_empty = not any(list)\n",
    "    # print(check_empty)\n",
    "    if check_empty == False:\n",
    "      news_df=pd.DataFrame(list) #creating dataframe\n",
    "      print(news_df)\n",
    "\n",
    "except Exception as e:\n",
    "    #exception handling\n",
    "    print(\"exception occurred:\" + str(e))\n",
    "    print('Looks like, there is some error in retrieving the data, Please try again or try with a different ticker.' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8773879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment Analysis\n",
    "def percentage(part,whole):\n",
    "    return 100 * float(part)/float(whole)\n",
    "\n",
    "#Assigning Initial Values\n",
    "positive = 0\n",
    "negative = 0\n",
    "neutral = 0\n",
    "#Creating empty lists\n",
    "news_list = []\n",
    "neutral_list = []\n",
    "negative_list = []\n",
    "positive_list = []\n",
    "\n",
    "#Iterating over the tweets in the dataframe\n",
    "for news in news_df['Summary']:\n",
    "    news_list.append(news)\n",
    "    analyzer = SentimentIntensityAnalyzer().polarity_scores(news)\n",
    "    neg = analyzer['neg']\n",
    "    neu = analyzer['neu']\n",
    "    pos = analyzer['pos']\n",
    "    comp = analyzer['compound']\n",
    "\n",
    "    if neg > pos:\n",
    "        negative_list.append(news) #appending the news that satisfies this condition\n",
    "        negative += 1 #increasing the count by 1\n",
    "    elif pos > neg:\n",
    "        positive_list.append(news) #appending the news that satisfies this condition\n",
    "        positive += 1 #increasing the count by 1\n",
    "    elif pos == neg:\n",
    "        neutral_list.append(news) #appending the news that satisfies this condition\n",
    "        neutral += 1 #increasing the count by 1 \n",
    "\n",
    "positive = percentage(positive, len(news_df)) #percentage is the function defined above\n",
    "negative = percentage(negative, len(news_df))\n",
    "neutral = percentage(neutral, len(news_df))\n",
    "\n",
    "#Converting lists to pandas dataframe\n",
    "news_list = pd.DataFrame(news_list)\n",
    "neutral_list = pd.DataFrame(neutral_list)\n",
    "negative_list = pd.DataFrame(negative_list)\n",
    "positive_list = pd.DataFrame(positive_list)\n",
    "#using len(length) function for counting\n",
    "print(\"Positive Sentiment:\", '%.2f' % len(positive_list), end='\\n')\n",
    "print(\"Neutral Sentiment:\", '%.2f' % len(neutral_list), end='\\n')\n",
    "print(\"Negative Sentiment:\", '%.2f' % len(negative_list), end='\\n')\n",
    "\n",
    "#Creating PieCart\n",
    "labels = ['Positive ['+str(round(positive))+'%]' , 'Neutral ['+str(round(neutral))+'%]','Negative ['+str(round(negative))+'%]']\n",
    "sizes = [positive, neutral, negative]\n",
    "colors = ['yellowgreen', 'blue','red']\n",
    "patches, texts = plt.pie(sizes,colors=colors, startangle=90)\n",
    "plt.style.use('default')\n",
    "plt.legend(labels)\n",
    "plt.title(\"Sentiment Analysis Result for stock= \"+company_name+\"\" )\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "# Word cloud visualization\n",
    "def word_cloud(text):\n",
    "    stopwords = set(STOPWORDS)\n",
    "    allWords = ' '.join([nws for nws in text])\n",
    "    wordCloud = WordCloud(background_color='black',width = 1600, height = 800,stopwords = stopwords,min_font_size = 20,max_font_size=150,colormap='prism').generate(allWords)\n",
    "    fig, ax = plt.subplots(figsize=(20,10), facecolor='k')\n",
    "    plt.imshow(wordCloud)\n",
    "    ax.axis(\"off\")\n",
    "    fig.tight_layout(pad=0)\n",
    "    plt.show()\n",
    "\n",
    "print('Wordcloud for ' + company_name)\n",
    "word_cloud(news_df['Summary'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ba00cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5d43c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
